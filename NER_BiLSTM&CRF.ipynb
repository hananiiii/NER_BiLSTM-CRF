{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wu3n8LhPZIAx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6BIW2OYZLQm",
        "outputId": "0a878847-4d3d-424b-d636-ff530c82898e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX6ZDs51bf21"
      },
      "source": [
        "self.transitions = table of rules: which crayon can follow which.\n",
        "\n",
        "self.start_transitions = which crayon is good to start.\n",
        "\n",
        "self.end_transitions = which crayon is good to end.\n",
        "\n",
        "reset_parameters = start with baby rules before learning real ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itzP4RkIZcc0"
      },
      "outputs": [],
      "source": [
        "class CRF(nn.Module):\n",
        "    \"\"\"Conditional Random Field layer for sequence labeling\"\"\"\n",
        "    def __init__(self, num_tags, batch_first=True):\n",
        "        super(CRF, self).__init__()\n",
        "        self.num_tags = num_tags\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        # Transition parameters: transitions[i, j] is the score of transitioning from j to i\n",
        "        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))\n",
        "\n",
        "        # Start and end transitions\n",
        "        self.start_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "        self.end_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "        self.reset_parameters()\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Initialize parameters\"\"\"\n",
        "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0DG3Ks-b34t"
      },
      "source": [
        "total score of all possible cases (per o loc ..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxsSleFdbhSM"
      },
      "outputs": [],
      "source": [
        "def _compute_partition_function(self, emissions, mask):\n",
        "        \"\"\"Compute the partition function using forward algorithm\"\"\"\n",
        "        #“emission scores” — how much each word (in a sentence) likes each possible tag. wth shape [batch_size, seq_length, num_tags]\n",
        "        # and only takes the 2 frst\n",
        "        batch_size, seq_length = emissions.size()[:2]\n",
        "\n",
        "        # Initialize forward variables ( first word in each sentence + how easy it is to start a sequence with each tag. [1,numtags] )\n",
        "        alpha = emissions[:, 0] + self.start_transitions.unsqueeze(0)\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            # Broadcast alpha for all possible next tags\n",
        "            #alpha has shape: [batch_size, num_tags]=>  [batch_size, num_tags,1] at position 2\n",
        "            broadcast_alpha = alpha.unsqueeze(2)  # (batch_size, num_tags, 1)\n",
        "\n",
        "            # Add transition scores If I’m in tag A, what’s the score of moving to tag B?\n",
        "            broadcast_transitions = self.transitions.unsqueeze(0)  # (1, num_tags, num_tags)\n",
        "\n",
        "            # Add emission scores\n",
        "            broadcast_emissions = emissions[:, i].unsqueeze(1)  # (batch_size, 1, num_tags)\n",
        "\n",
        "            # Compute next alpha\n",
        "            next_alpha = broadcast_alpha + broadcast_transitions + broadcast_emissions\n",
        "\n",
        "            # Log-sum-exp\n",
        "            next_alpha = torch.logsumexp(next_alpha, dim=1)\n",
        "\n",
        "            # Apply mask\n",
        "            alpha = torch.where(mask[:, i].unsqueeze(1), next_alpha, alpha)\n",
        "\n",
        "        # Add end transitions\n",
        "        alpha = alpha + self.end_transitions.unsqueeze(0)\n",
        "\n",
        "        # Sum over all tags\n",
        "        return torch.logsumexp(alpha, dim=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
